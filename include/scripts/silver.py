from include.scripts.spark_utils import get_spark_session
from pyspark.sql.functions import (
    col,
    to_timestamp,
    current_timestamp,
    trim,
    upper,
    lit,
    regexp_replace,
    when,
)
from pyspark.sql.types import DoubleType


def process_silver():
    """
    Processa GPS aplicando o Dicion√°rio de Dados da PBH.
    """
    spark = get_spark_session("SilverLayer")
    bronze_path = "/opt/airflow/data/bronze/bus_position/*/*.parquet"

    try:
        df = spark.read.parquet(bronze_path)
    except Exception:
        print("‚ö†Ô∏è Bronze Bus vazia.")
        return

    print(f"üìä Colunas na Bronze: {df.columns}")

    # --- MAPEAMENTO CONFORME DICION√ÅRIO ---
    # LT -> Latitude
    # LG -> Longitude
    # NV -> N√∫mero Ve√≠culo
    # NL -> C√≥digo Linha
    # HR -> DataHora (AnoMesDiaHoraMinutoSegundo)

    # 1. Renomea√ß√£o Segura (verifica se a coluna existe antes)
    mappings = {
        "LT": "latitude",
        "LG": "longitude",
        "NV": "numero_do_veiculo",
        "NL": "cod_linha",
        "HR": "datahora_raw",
    }

    for old_col, new_col in mappings.items():
        if old_col in df.columns:
            df = df.withColumnRenamed(old_col, new_col)

    # 2. Convers√£o de Tipos
    # Latitude/Longitude (PBH usa v√≠rgula decimal ex: -19,123)
    if "latitude" in df.columns:
        df = df.withColumn(
            "latitude", regexp_replace(col("latitude"), ",", ".").cast(DoubleType())
        )

    if "longitude" in df.columns:
        df = df.withColumn(
            "longitude", regexp_replace(col("longitude"), ",", ".").cast(DoubleType())
        )

    # Timestamp (Formato YYYYMMDDHHMMSS)
    if "datahora_raw" in df.columns:
        df = df.withColumn(
            "event_timestamp", to_timestamp(col("datahora_raw"), "yyyyMMddHHmmss")
        )
    else:
        # Fallback se n√£o tiver HR
        df = df.withColumn("event_timestamp", current_timestamp())

    df = df.withColumn("_processed_at", current_timestamp())

    # 3. Filtragem e Deduplica√ß√£o
    required_cols = ["latitude", "longitude", "numero_do_veiculo", "event_timestamp"]
    # Verifica se colunas existem antes de filtrar
    valid_cols = [c for c in required_cols if c in df.columns]

    if len(valid_cols) == 4:
        df_final = df.filter(
            col("latitude").isNotNull() & col("longitude").isNotNull()
        ).dropDuplicates(["numero_do_veiculo", "event_timestamp"])
    else:
        print(
            f"‚ö†Ô∏è Faltando colunas essenciais para Silver: {set(required_cols) - set(df.columns)}"
        )
        df_final = df  # Salva o que tem para debug

    # 4. Salvar
    silver_path = "/opt/airflow/data/silver/bus_position"
    df_final.write.format("delta").mode("overwrite").option(
        "overwriteSchema", "true"
    ).save(silver_path)
    print(f"‚úÖ Silver BUS salva em: {silver_path}")


def process_mco_silver():
    """
    Processa MCO para extrair Dimens√£o de Linhas.
    Baseado no Dicion√°rio Oficial: Usamos colunas 'LINHA' e 'CONCESSION√ÅRIA'.
    """
    spark = get_spark_session("SilverMCO")
    bronze_path = "/opt/airflow/data/bronze/mco/*/*.parquet"

    try:
        df = spark.read.parquet(bronze_path)
    except Exception:
        print("‚ö†Ô∏è Bronze MCO vazia.")
        return

    print(f"üìä Colunas MCO Bronze: {df.columns}")

    # --- MAPEAMENTO BASEADO NO PDF DO MCO ---
    # Coluna 'LINHA' -> C√≥digo da Linha (ex: SC01A)
    # Coluna 'CONCESSION√ÅRIA' -> C√≥digo do Cons√≥rcio (ex: 801)

    # 1. Verifica colunas dispon√≠veis
    has_linha = "LINHA" in df.columns
    has_conc = (
        "CONCESSION√ÅRIA" in df.columns or "CONCESSIONARIA" in df.columns
    )  # Sem acento por seguran√ßa

    if not has_linha:
        print("‚ùå Erro Cr√≠tico: Coluna 'LINHA' n√£o encontrada no arquivo MCO.")
        # Tenta listar colunas para debug do usu√°rio
        print(f"Colunas dispon√≠veis: {df.columns}")
        return

    # Normaliza nome da coluna de Concession√°ria (com ou sem acento)
    col_conc = "CONCESSION√ÅRIA" if "CONCESSION√ÅRIA" in df.columns else "CONCESSIONARIA"

    # 2. Seleciona e Renomeia
    df_dim = df.select(
        col("LINHA").alias("cod_linha"), col(col_conc).alias("consorcio")
    ).distinct()  # Pega apenas linhas √∫nicas, ignorando as milh√µes de viagens

    # 3. Tratamento
    df_clean = (
        df_dim.withColumn("cod_linha", trim(upper(col("cod_linha"))))
        .withColumn("consorcio", trim(upper(col("consorcio"))))
        .withColumn("nome_linha", lit("N/A - Ver MCO"))
    )  # Placeholder pois MCO n√£o tem nome descritivo

    # 4. Salva Silver
    silver_path = "/opt/airflow/data/silver/mco"
    df_clean.write.format("delta").mode("overwrite").option(
        "overwriteSchema", "true"
    ).save(silver_path)
    print(f"‚úÖ Silver MCO (Dimens√£o Extra√≠da) salva em {silver_path}")
